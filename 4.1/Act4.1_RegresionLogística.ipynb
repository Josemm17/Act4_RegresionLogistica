{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a321363a",
   "metadata": {},
   "source": [
    "# **Actividad 4.1 (Regresión Logística)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbb613d",
   "metadata": {},
   "source": [
    "## Carga y preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa95ab09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>name</th>\n",
       "      <th>host_since</th>\n",
       "      <th>host_location</th>\n",
       "      <th>host_response_time</th>\n",
       "      <th>host_is_superhost</th>\n",
       "      <th>host_neighbourhood</th>\n",
       "      <th>host_identity_verified</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>neighbourhood_cleansed</th>\n",
       "      <th>...</th>\n",
       "      <th>review_scores_cleanliness</th>\n",
       "      <th>review_scores_checkin</th>\n",
       "      <th>review_scores_communication</th>\n",
       "      <th>review_scores_location</th>\n",
       "      <th>review_scores_value</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>calculated_host_listings_count_entire_homes</th>\n",
       "      <th>calculated_host_listings_count_private_rooms</th>\n",
       "      <th>calculated_host_listings_count_shared_rooms</th>\n",
       "      <th>reviews_per_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>city scrape</td>\n",
       "      <td>Unbelievable Ocean View Apartment</td>\n",
       "      <td>2011-11-19</td>\n",
       "      <td>Rio de Janeiro, Brazil</td>\n",
       "      <td>a few days or more</td>\n",
       "      <td>f</td>\n",
       "      <td>Vidigal</td>\n",
       "      <td>t</td>\n",
       "      <td>Rio de Janeiro, Brazil</td>\n",
       "      <td>Vidigal</td>\n",
       "      <td>...</td>\n",
       "      <td>4.90</td>\n",
       "      <td>4.90</td>\n",
       "      <td>4.90</td>\n",
       "      <td>4.90</td>\n",
       "      <td>4.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>city scrape</td>\n",
       "      <td>EXCELENTE APARTAMENTO EM COPACABANA</td>\n",
       "      <td>2013-07-15</td>\n",
       "      <td>Rio de Janeiro, Brazil</td>\n",
       "      <td>Sin registro</td>\n",
       "      <td>f</td>\n",
       "      <td>Sin registro</td>\n",
       "      <td>f</td>\n",
       "      <td>Rio de Janeiro, Brazil</td>\n",
       "      <td>Copacabana</td>\n",
       "      <td>...</td>\n",
       "      <td>4.87</td>\n",
       "      <td>4.97</td>\n",
       "      <td>4.97</td>\n",
       "      <td>4.97</td>\n",
       "      <td>4.86</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>city scrape</td>\n",
       "      <td>Comfort em Copacabana</td>\n",
       "      <td>2011-11-20</td>\n",
       "      <td>Rio de Janeiro, Brazil</td>\n",
       "      <td>within an hour</td>\n",
       "      <td>t</td>\n",
       "      <td>Copacabana</td>\n",
       "      <td>t</td>\n",
       "      <td>Sin registro</td>\n",
       "      <td>Copacabana</td>\n",
       "      <td>...</td>\n",
       "      <td>4.94</td>\n",
       "      <td>4.94</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.97</td>\n",
       "      <td>4.94</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>city scrape</td>\n",
       "      <td>Amazing Huge Apartment in Leblon</td>\n",
       "      <td>2011-04-25</td>\n",
       "      <td>Rio de Janeiro, Brazil</td>\n",
       "      <td>Sin registro</td>\n",
       "      <td>f</td>\n",
       "      <td>Leblon</td>\n",
       "      <td>f</td>\n",
       "      <td>Sin registro</td>\n",
       "      <td>Leblon</td>\n",
       "      <td>...</td>\n",
       "      <td>4.80</td>\n",
       "      <td>4.90</td>\n",
       "      <td>4.90</td>\n",
       "      <td>4.90</td>\n",
       "      <td>4.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>city scrape</td>\n",
       "      <td>Lindo quarto sossegado para temporada</td>\n",
       "      <td>2011-05-04</td>\n",
       "      <td>Rio de Janeiro, Brazil</td>\n",
       "      <td>within a few hours</td>\n",
       "      <td>f</td>\n",
       "      <td>Santa Teresa</td>\n",
       "      <td>t</td>\n",
       "      <td>Rio de Janeiro, Brazil</td>\n",
       "      <td>Santa Teresa</td>\n",
       "      <td>...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.90</td>\n",
       "      <td>4.80</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        source                                   name  host_since  \\\n",
       "0  city scrape      Unbelievable Ocean View Apartment  2011-11-19   \n",
       "1  city scrape    EXCELENTE APARTAMENTO EM COPACABANA  2013-07-15   \n",
       "2  city scrape                  Comfort em Copacabana  2011-11-20   \n",
       "3  city scrape       Amazing Huge Apartment in Leblon  2011-04-25   \n",
       "4  city scrape  Lindo quarto sossegado para temporada  2011-05-04   \n",
       "\n",
       "            host_location  host_response_time host_is_superhost  \\\n",
       "0  Rio de Janeiro, Brazil  a few days or more                 f   \n",
       "1  Rio de Janeiro, Brazil        Sin registro                 f   \n",
       "2  Rio de Janeiro, Brazil      within an hour                 t   \n",
       "3  Rio de Janeiro, Brazil        Sin registro                 f   \n",
       "4  Rio de Janeiro, Brazil  within a few hours                 f   \n",
       "\n",
       "  host_neighbourhood host_identity_verified           neighbourhood  \\\n",
       "0            Vidigal                      t  Rio de Janeiro, Brazil   \n",
       "1       Sin registro                      f  Rio de Janeiro, Brazil   \n",
       "2         Copacabana                      t            Sin registro   \n",
       "3             Leblon                      f            Sin registro   \n",
       "4       Santa Teresa                      t  Rio de Janeiro, Brazil   \n",
       "\n",
       "  neighbourhood_cleansed  ... review_scores_cleanliness review_scores_checkin  \\\n",
       "0                Vidigal  ...                      4.90                  4.90   \n",
       "1             Copacabana  ...                      4.87                  4.97   \n",
       "2             Copacabana  ...                      4.94                  4.94   \n",
       "3                 Leblon  ...                      4.80                  4.90   \n",
       "4           Santa Teresa  ...                      5.00                  5.00   \n",
       "\n",
       "  review_scores_communication review_scores_location review_scores_value  \\\n",
       "0                        4.90                   4.90                4.80   \n",
       "1                        4.97                   4.97                4.86   \n",
       "2                        5.00                   4.97                4.94   \n",
       "3                        4.90                   4.90                4.70   \n",
       "4                        5.00                   4.90                4.80   \n",
       "\n",
       "  calculated_host_listings_count  calculated_host_listings_count_entire_homes  \\\n",
       "0                            1.0                                          1.0   \n",
       "1                            2.0                                          2.0   \n",
       "2                            5.0                                          3.0   \n",
       "3                            1.0                                          1.0   \n",
       "4                            5.0                                          0.0   \n",
       "\n",
       "   calculated_host_listings_count_private_rooms  \\\n",
       "0                                           0.0   \n",
       "1                                           0.0   \n",
       "2                                           2.0   \n",
       "3                                           0.0   \n",
       "4                                           0.3   \n",
       "\n",
       "   calculated_host_listings_count_shared_rooms  reviews_per_month  \n",
       "0                                          0.0               0.05  \n",
       "1                                          0.0               2.31  \n",
       "2                                          0.0               0.25  \n",
       "3                                          0.0               1.20  \n",
       "4                                          0.0               0.04  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "df=pd.read_csv(\"Rio_limpio.csv\", index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ecbf2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instant_bookable\n",
      "f    29211\n",
      "t     8626\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = df[df['host_is_superhost'] != 'Sin registro']\n",
    "df = df[df['host_identity_verified'] != 'Sin registro']\n",
    "df = df[df['has_availability'] != 'Sin registro']\n",
    "df = df[df['instant_bookable'] != 'Sin registro']\n",
    "\n",
    "print(df[\"instant_bookable\"].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18b2257",
   "metadata": {},
   "source": [
    "## Analizar 10 casos de correlación logística que existe entre diferentes variables de nuestra base de datos, aplicando la herramienta de **“Regresión Logística”**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f541a34",
   "metadata": {},
   "source": [
    "### host_is_superhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32190bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión:\n",
      "[[7350  371]\n",
      " [2914  717]]\n",
      "\n",
      "\n",
      "Precision del modelo t:\n",
      "0.6590073529411765\n",
      "Precision del modelo f:\n",
      "0.7160950896336711\n",
      "\n",
      "\n",
      "Exactitud del modelo:\n",
      "0.7106236786469344\n",
      "\n",
      "\n",
      "Sensibilidad del modelo t:\n",
      "0.19746626273753787\n",
      "Sensibilidad del modelo f:\n",
      "0.9519492293744334\n"
     ]
    }
   ],
   "source": [
    "Vars_Indep=df[[\"price\", \"beds\", \"review_scores_cleanliness\", \"bathrooms\", \"review_scores_value\", \"review_scores_location\", \"reviews_per_month\"]]\n",
    "Var_dep=df[\"host_is_superhost\"]\n",
    "\n",
    "X=Vars_Indep\n",
    "y=Var_dep\n",
    "\n",
    "#Dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=None)\n",
    "\n",
    "#Escalar los datos\n",
    "escalar= StandardScaler()\n",
    "\n",
    "X_train=escalar.fit_transform(X_train)\n",
    "X_test=escalar.fit_transform(X_test)\n",
    "\n",
    "#Definir el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo=LogisticRegression()\n",
    "\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "y_pred=algoritmo.predict(X_test)\n",
    "\n",
    "#Matriz de confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz=confusion_matrix(y_test, y_pred)\n",
    "print(\"Matriz de confusión:\")\n",
    "print(matriz)\n",
    "print(\"\\n\")\n",
    "\n",
    "#Calcular la precisión\n",
    "from sklearn.metrics import precision_score\n",
    "precision1=precision_score(y_test, y_pred, average=\"binary\", pos_label=\"t\")\n",
    "precision2=precision_score(y_test, y_pred, average=\"binary\", pos_label=\"f\")\n",
    "\n",
    "#Calcular la exactitud\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud=accuracy_score(y_test, y_pred)\n",
    "\n",
    "#Calcular la sensibilidad\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad1=recall_score(y_test, y_pred, average=\"binary\", pos_label=\"t\")\n",
    "sensibilidad2=recall_score(y_test, y_pred, average=\"binary\", pos_label=\"f\")\n",
    "\n",
    "print(\"Precision del modelo t:\")\n",
    "print(precision1)\n",
    "print(\"Precision del modelo f:\")\n",
    "print(precision2)\n",
    "print(\"\\n\")\n",
    "print(\"Exactitud del modelo:\")\n",
    "print(exactitud)\n",
    "print(\"\\n\")\n",
    "print(\"Sensibilidad del modelo t:\")\n",
    "print(sensibilidad1)\n",
    "print(\"Sensibilidad del modelo f:\")\n",
    "print(sensibilidad2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db06705d",
   "metadata": {},
   "source": [
    "### host_identity_verified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "530de2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión:\n",
      "[[   0 1829]\n",
      " [   0 9523]]\n",
      "\n",
      "\n",
      "Precision del modelo t:\n",
      "0.8388830162085976\n",
      "Precision del modelo f:\n",
      "0.0\n",
      "\n",
      "\n",
      "Exactitud del modelo:\n",
      "0.8388830162085976\n",
      "\n",
      "\n",
      "Sensibilidad del modelo t:\n",
      "1.0\n",
      "Sensibilidad del modelo f:\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "Vars_Indep=df[[\"price\", \"beds\", \"review_scores_cleanliness\", \"bathrooms\", \"review_scores_value\", \"review_scores_location\", \"reviews_per_month\"]]\n",
    "Var_dep=df[\"host_identity_verified\"]\n",
    "\n",
    "X=Vars_Indep\n",
    "y=Var_dep\n",
    "\n",
    "#Dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=None)\n",
    "\n",
    "#Escalar los datos\n",
    "escalar= StandardScaler()\n",
    "\n",
    "X_train=escalar.fit_transform(X_train)\n",
    "X_test=escalar.fit_transform(X_test)\n",
    "\n",
    "#Definir el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo=LogisticRegression()\n",
    "\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "y_pred=algoritmo.predict(X_test)\n",
    "\n",
    "#Matriz de confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz=confusion_matrix(y_test, y_pred)\n",
    "print(\"Matriz de confusión:\")\n",
    "print(matriz)\n",
    "print(\"\\n\")\n",
    "\n",
    "#Calcular la precisión\n",
    "from sklearn.metrics import precision_score\n",
    "precision1=precision_score(y_test, y_pred, average=\"binary\", pos_label=\"t\")\n",
    "precision2=precision_score(y_test, y_pred, average=\"binary\", pos_label=\"f\")\n",
    "\n",
    "#Calcular la exactitud\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud=accuracy_score(y_test, y_pred)\n",
    "\n",
    "#Calcular la sensibilidad\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad1=recall_score(y_test, y_pred, average=\"binary\", pos_label=\"t\")\n",
    "sensibilidad2=recall_score(y_test, y_pred, average=\"binary\", pos_label=\"f\")\n",
    "\n",
    "print(\"Precision del modelo t:\")\n",
    "print(precision1)\n",
    "print(\"Precision del modelo f:\")\n",
    "print(precision2)\n",
    "print(\"\\n\")\n",
    "print(\"Exactitud del modelo:\")\n",
    "print(exactitud)\n",
    "print(\"\\n\")\n",
    "print(\"Sensibilidad del modelo t:\")\n",
    "print(sensibilidad1)\n",
    "print(\"Sensibilidad del modelo f:\")\n",
    "print(sensibilidad2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a51280",
   "metadata": {},
   "source": [
    "### has_availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7bc918fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión:\n",
      "[[11352]]\n",
      "\n",
      "\n",
      "Precision del modelo t:\n",
      "1.0\n",
      "Precision del modelo f:\n",
      "0.0\n",
      "\n",
      "\n",
      "Exactitud del modelo:\n",
      "1.0\n",
      "\n",
      "\n",
      "Sensibilidad del modelo t:\n",
      "1.0\n",
      "Sensibilidad del modelo f:\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "Vars_Indep=df[[\"price\", \"beds\", \"review_scores_cleanliness\", \"bathrooms\", \"review_scores_value\", \"review_scores_location\", \"reviews_per_month\"]]\n",
    "Var_dep=df[\"has_availability\"]\n",
    "\n",
    "X=Vars_Indep\n",
    "y=Var_dep\n",
    "\n",
    "#Dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=None)\n",
    "\n",
    "#Escalar los datos\n",
    "escalar= StandardScaler()\n",
    "\n",
    "X_train=escalar.fit_transform(X_train)\n",
    "X_test=escalar.fit_transform(X_test)\n",
    "\n",
    "#Definir el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo=LogisticRegression()\n",
    "\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "y_pred=algoritmo.predict(X_test)\n",
    "\n",
    "#Matriz de confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz=confusion_matrix(y_test, y_pred)\n",
    "print(\"Matriz de confusión:\")\n",
    "print(matriz)\n",
    "print(\"\\n\")\n",
    "\n",
    "#Calcular la precisión\n",
    "from sklearn.metrics import precision_score\n",
    "precision1=precision_score(y_test, y_pred, average=\"binary\", pos_label=\"t\")\n",
    "precision2=precision_score(y_test, y_pred, average=\"binary\", pos_label=\"f\")\n",
    "\n",
    "#Calcular la exactitud\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud=accuracy_score(y_test, y_pred)\n",
    "\n",
    "#Calcular la sensibilidad\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad1=recall_score(y_test, y_pred, average=\"binary\", pos_label=\"t\")\n",
    "sensibilidad2=recall_score(y_test, y_pred, average=\"binary\", pos_label=\"f\")\n",
    "\n",
    "print(\"Precision del modelo t:\")\n",
    "print(precision1)\n",
    "print(\"Precision del modelo f:\")\n",
    "print(precision2)\n",
    "print(\"\\n\")\n",
    "print(\"Exactitud del modelo:\")\n",
    "print(exactitud)\n",
    "print(\"\\n\")\n",
    "print(\"Sensibilidad del modelo t:\")\n",
    "print(sensibilidad1)\n",
    "print(\"Sensibilidad del modelo f:\")\n",
    "print(sensibilidad2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8c625a",
   "metadata": {},
   "source": [
    "### instant_bookable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8728e82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión:\n",
      "[[8799    1]\n",
      " [2550    2]]\n",
      "\n",
      "\n",
      "Precision del modelo t:\n",
      "0.6666666666666666\n",
      "Precision del modelo f:\n",
      "0.7753106000528681\n",
      "\n",
      "\n",
      "Exactitud del modelo:\n",
      "0.7752818886539817\n",
      "\n",
      "\n",
      "Sensibilidad del modelo t:\n",
      "0.0007836990595611285\n",
      "Sensibilidad del modelo f:\n",
      "0.9998863636363636\n"
     ]
    }
   ],
   "source": [
    "Vars_Indep=df[[\"price\", \"beds\", \"review_scores_cleanliness\", \"bathrooms\", \"review_scores_value\", \"review_scores_location\", \"reviews_per_month\"]]\n",
    "Var_dep=df[\"instant_bookable\"]\n",
    "\n",
    "X=Vars_Indep\n",
    "y=Var_dep\n",
    "\n",
    "#Dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=None)\n",
    "\n",
    "#Escalar los datos\n",
    "escalar= StandardScaler()\n",
    "\n",
    "X_train=escalar.fit_transform(X_train)\n",
    "X_test=escalar.fit_transform(X_test)\n",
    "\n",
    "#Definir el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo=LogisticRegression()\n",
    "\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "y_pred=algoritmo.predict(X_test)\n",
    "\n",
    "#Matriz de confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz=confusion_matrix(y_test, y_pred)\n",
    "print(\"Matriz de confusión:\")\n",
    "print(matriz)\n",
    "print(\"\\n\")\n",
    "\n",
    "#Calcular la precisión\n",
    "from sklearn.metrics import precision_score\n",
    "precision1=precision_score(y_test, y_pred, average=\"binary\", pos_label=\"t\")\n",
    "precision2=precision_score(y_test, y_pred, average=\"binary\", pos_label=\"f\")\n",
    "\n",
    "#Calcular la exactitud\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud=accuracy_score(y_test, y_pred)\n",
    "\n",
    "#Calcular la sensibilidad\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad1=recall_score(y_test, y_pred, average=\"binary\", pos_label=\"t\")\n",
    "sensibilidad2=recall_score(y_test, y_pred, average=\"binary\", pos_label=\"f\")\n",
    "\n",
    "print(\"Precision del modelo t:\")\n",
    "print(precision1)\n",
    "print(\"Precision del modelo f:\")\n",
    "print(precision2)\n",
    "print(\"\\n\")\n",
    "print(\"Exactitud del modelo:\")\n",
    "print(exactitud)\n",
    "print(\"\\n\")\n",
    "print(\"Sensibilidad del modelo t:\")\n",
    "print(sensibilidad1)\n",
    "print(\"Sensibilidad del modelo f:\")\n",
    "print(sensibilidad2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf677267",
   "metadata": {},
   "source": [
    "### host_response_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1460ccc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificar los valores sin repetirse de una columna\n",
    "unico=np.unique(df[\"host_response_time\"])\n",
    "unico\n",
    "\n",
    "#CONVERTIR UNA VARIABLE CATEGÓRICA A DICOTÓMICA\n",
    "\n",
    "df[\"host_response_time\"]=df[\"host_response_time\"].replace([\"Sin registro\", \"a few days or more\", \"within a day\",\"within a few hours\"], \"More than an hour\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3137ef2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión:\n",
      "[[1939 3153]\n",
      " [1512 4748]]\n",
      "\n",
      "\n",
      "Precision del modelo within an hour:\n",
      "0.6009365903050247\n",
      "Precision del modelo More than an hour:\n",
      "0.5618661257606491\n",
      "\n",
      "\n",
      "Exactitud del modelo:\n",
      "0.5890591966173362\n",
      "\n",
      "\n",
      "Sensibilidad del modelo within an hour:\n",
      "0.7584664536741214\n",
      "Sensibilidad del modelo More than an hour:\n",
      "0.3807934014139827\n"
     ]
    }
   ],
   "source": [
    "Vars_Indep=df[[\"price\", \"beds\", \"review_scores_cleanliness\", \"bathrooms\", \"review_scores_value\", \"review_scores_location\", \"reviews_per_month\"]]\n",
    "Var_dep=df[\"host_response_time\"]\n",
    "\n",
    "X=Vars_Indep\n",
    "y=Var_dep\n",
    "\n",
    "#Dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=None)\n",
    "\n",
    "#Escalar los datos\n",
    "escalar= StandardScaler()\n",
    "\n",
    "X_train=escalar.fit_transform(X_train)\n",
    "X_test=escalar.fit_transform(X_test)\n",
    "\n",
    "#Definir el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo=LogisticRegression()\n",
    "\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "y_pred=algoritmo.predict(X_test)\n",
    "\n",
    "#Matriz de confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz=confusion_matrix(y_test, y_pred)\n",
    "print(\"Matriz de confusión:\")\n",
    "print(matriz)\n",
    "print(\"\\n\")\n",
    "\n",
    "#Calcular la precisión\n",
    "from sklearn.metrics import precision_score\n",
    "precision1=precision_score(y_test, y_pred, average=\"binary\", pos_label=\"within an hour\")\n",
    "precision2=precision_score(y_test, y_pred, average=\"binary\", pos_label=\"More than an hour\")\n",
    "\n",
    "#Calcular la exactitud\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud=accuracy_score(y_test, y_pred)\n",
    "\n",
    "#Calcular la sensibilidad\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad1=recall_score(y_test, y_pred, average=\"binary\", pos_label=\"within an hour\")\n",
    "sensibilidad2=recall_score(y_test, y_pred, average=\"binary\", pos_label=\"More than an hour\")\n",
    "\n",
    "print(\"Precision del modelo within an hour:\")\n",
    "print(precision1)\n",
    "print(\"Precision del modelo More than an hour:\")\n",
    "print(precision2)\n",
    "print(\"\\n\")\n",
    "print(\"Exactitud del modelo:\")\n",
    "print(exactitud)\n",
    "print(\"\\n\")\n",
    "print(\"Sensibilidad del modelo within an hour:\")\n",
    "print(sensibilidad1)\n",
    "print(\"Sensibilidad del modelo More than an hour:\")\n",
    "print(sensibilidad2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8ba9b0",
   "metadata": {},
   "source": [
    "### room_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c777e4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificar los valores sin repetirse de una columna\n",
    "unico=np.unique(df[\"room_type\"])\n",
    "unico\n",
    "\n",
    "#CONVERTIR UNA VARIABLE CATEGÓRICA A DICOTÓMICA\n",
    "\n",
    "df[\"room_type\"]=df[\"room_type\"].replace([\"Hotel room\", \"Private room\", \"Shared room\"], \"Otro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f5a3d43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión:\n",
      "[[8844  197]\n",
      " [1894  417]]\n",
      "\n",
      "\n",
      "Precision del modelo Entire home/apt:\n",
      "0.8236170609051965\n",
      "Precision del modelo Otro:\n",
      "0.6791530944625407\n",
      "\n",
      "\n",
      "Exactitud del modelo:\n",
      "0.8158033826638478\n",
      "\n",
      "\n",
      "Sensibilidad del modelo Entire home/apt:\n",
      "0.9782103749585223\n",
      "Sensibilidad del modelo Otro:\n",
      "0.18044136737343142\n"
     ]
    }
   ],
   "source": [
    "Vars_Indep=df[[\"price\", \"beds\", \"review_scores_cleanliness\", \"bathrooms\", \"review_scores_value\", \"review_scores_location\", \"reviews_per_month\"]]\n",
    "Var_dep=df[\"room_type\"]\n",
    "\n",
    "X=Vars_Indep\n",
    "y=Var_dep\n",
    "\n",
    "#Dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=None)\n",
    "\n",
    "#Escalar los datos\n",
    "escalar= StandardScaler()\n",
    "\n",
    "X_train=escalar.fit_transform(X_train)\n",
    "X_test=escalar.fit_transform(X_test)\n",
    "\n",
    "#Definir el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo=LogisticRegression()\n",
    "\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "y_pred=algoritmo.predict(X_test)\n",
    "\n",
    "\n",
    "#Matriz de confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz=confusion_matrix(y_test, y_pred)\n",
    "print(\"Matriz de confusión:\")\n",
    "print(matriz)\n",
    "print(\"\\n\")\n",
    "\n",
    "#Calcular la precisión\n",
    "from sklearn.metrics import precision_score\n",
    "precision1=precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Entire home/apt\")\n",
    "precision2=precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Otro\")\n",
    "\n",
    "#Calcular la exactitud\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud=accuracy_score(y_test, y_pred)\n",
    "\n",
    "#Calcular la sensibilidad\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad1=recall_score(y_test, y_pred, average=\"binary\", pos_label=\"Entire home/apt\")\n",
    "sensibilidad2=recall_score(y_test, y_pred, average=\"binary\", pos_label=\"Otro\")\n",
    "\n",
    "print(\"Precision del modelo Entire home/apt:\")\n",
    "print(precision1)\n",
    "print(\"Precision del modelo Otro:\")\n",
    "print(precision2)\n",
    "print(\"\\n\")\n",
    "print(\"Exactitud del modelo:\")\n",
    "print(exactitud)\n",
    "print(\"\\n\")\n",
    "print(\"Sensibilidad del modelo Entire home/apt:\")\n",
    "print(sensibilidad1)\n",
    "print(\"Sensibilidad del modelo Otro:\")\n",
    "print(sensibilidad2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201b0836",
   "metadata": {},
   "source": [
    "### availability_365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4dcf5ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.int64(0), np.int64(365)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Crear categorias a partir de clases\n",
    "Max=df[\"availability_365\"].max()\n",
    "Min=df[\"availability_365\"].min()\n",
    "\n",
    "\n",
    "limites=[Min, Max]\n",
    "limites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb524c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declarar dos intervalos\n",
    "intervalos=np.linspace(-0.1,365.1, 3)\n",
    "intervalos\n",
    "\n",
    "categorias=[\"Disponibilidad menor a medio año\", \"Disponibilidad mayor a medio año\"]\n",
    "\n",
    "df[\"availability_365\"]=pd.cut(x=df[\"availability_365\"], bins=intervalos, labels=categorias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b803a7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión:\n",
      "[[2067 3265]\n",
      " [1682 4338]]\n",
      "\n",
      "\n",
      "Precision del modelo Disponibilidad menor a medio año:\n",
      "0.570564250953571\n",
      "Precision del modelo Disponibilidad mayor a medio año:\n",
      "0.5513470258735663\n",
      "\n",
      "\n",
      "Exactitud del modelo:\n",
      "0.5642177589852009\n",
      "\n",
      "\n",
      "Sensibilidad del modelo Disponibilidad menor a medio año:\n",
      "0.7205980066445182\n",
      "Sensibilidad del modelo Disponibilidad mayor a medio año:\n",
      "0.3876594148537134\n"
     ]
    }
   ],
   "source": [
    "Vars_Indep=df[[\"price\", \"beds\", \"review_scores_cleanliness\", \"bathrooms\", \"review_scores_value\", \"review_scores_location\", \"reviews_per_month\"]]\n",
    "Var_dep=df[\"availability_365\"]\n",
    "\n",
    "X=Vars_Indep\n",
    "y=Var_dep\n",
    "\n",
    "#Dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=None)\n",
    "\n",
    "#Escalar los datos\n",
    "escalar= StandardScaler()\n",
    "\n",
    "X_train=escalar.fit_transform(X_train)\n",
    "X_test=escalar.fit_transform(X_test)\n",
    "\n",
    "#Definir el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo=LogisticRegression()\n",
    "\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "y_pred=algoritmo.predict(X_test)\n",
    "\n",
    "#Matriz de confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz=confusion_matrix(y_test, y_pred)\n",
    "print(\"Matriz de confusión:\")\n",
    "print(matriz)\n",
    "print(\"\\n\")\n",
    "\n",
    "#Calcular la precisión\n",
    "from sklearn.metrics import precision_score\n",
    "precision1=precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Disponibilidad menor a medio año\")\n",
    "precision2=precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Disponibilidad mayor a medio año\")\n",
    "\n",
    "#Calcular la exactitud\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud=accuracy_score(y_test, y_pred)\n",
    "\n",
    "#Calcular la sensibilidad\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad1=recall_score(y_test, y_pred, average=\"binary\", pos_label=\"Disponibilidad menor a medio año\")\n",
    "sensibilidad2=recall_score(y_test, y_pred, average=\"binary\", pos_label=\"Disponibilidad mayor a medio año\")\n",
    "\n",
    "print(\"Precision del modelo Disponibilidad menor a medio año:\")\n",
    "print(precision1)\n",
    "print(\"Precision del modelo Disponibilidad mayor a medio año:\")\n",
    "print(precision2)\n",
    "print(\"\\n\")\n",
    "print(\"Exactitud del modelo:\")\n",
    "print(exactitud)\n",
    "print(\"\\n\")\n",
    "print(\"Sensibilidad del modelo Disponibilidad menor a medio año:\")\n",
    "print(sensibilidad1)\n",
    "print(\"Sensibilidad del modelo Disponibilidad mayor a medio año:\")\n",
    "print(sensibilidad2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308421b3",
   "metadata": {},
   "source": [
    "### availability_30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5285a05e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.int64(0), np.int64(30)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Crear categorias a partir de clases\n",
    "Max=df[\"availability_30\"].max()\n",
    "Min=df[\"availability_30\"].min()\n",
    "\n",
    "\n",
    "limites=[Min, Max]\n",
    "limites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eaff72f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declarar dos intervalos\n",
    "intervalos=np.linspace(-0.1,30.1, 3)\n",
    "intervalos\n",
    "\n",
    "categorias=[\"Poca disponibilidad en el siguiente mes\", \"Mucha disponibilidad en el siguiente mes\"]\n",
    "\n",
    "df[\"availability_30\"]=pd.cut(x=df[\"availability_30\"], bins=intervalos, labels=categorias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "05f9dd54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión:\n",
      "[[3107 2473]\n",
      " [2280 3492]]\n",
      "\n",
      "\n",
      "Precision del modelo Mucha disponibilidad en el siguiente mes:\n",
      "0.5767588639316874\n",
      "Precision del modelo Poca disponibilidad en el siguiente mes:\n",
      "0.5854149203688181\n",
      "\n",
      "\n",
      "Exactitud del modelo:\n",
      "0.58130725863284\n",
      "\n",
      "\n",
      "Sensibilidad del modelo Mucha disponibilidad en el siguiente mes:\n",
      "0.5568100358422939\n",
      "Sensibilidad del modelo Poca disponibilidad en el siguiente mes:\n",
      "0.604989604989605\n"
     ]
    }
   ],
   "source": [
    "Vars_Indep=df[[\"price\", \"beds\", \"review_scores_cleanliness\", \"bathrooms\", \"review_scores_value\", \"review_scores_location\", \"reviews_per_month\"]]\n",
    "Var_dep=df[\"availability_30\"]\n",
    "\n",
    "X=Vars_Indep\n",
    "y=Var_dep\n",
    "\n",
    "#Dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=None)\n",
    "\n",
    "#Escalar los datos\n",
    "escalar= StandardScaler()\n",
    "\n",
    "X_train=escalar.fit_transform(X_train)\n",
    "X_test=escalar.fit_transform(X_test)\n",
    "\n",
    "#Definir el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo=LogisticRegression()\n",
    "\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "y_pred=algoritmo.predict(X_test)\n",
    "\n",
    "#Matriz de confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz=confusion_matrix(y_test, y_pred)\n",
    "print(\"Matriz de confusión:\")\n",
    "print(matriz)\n",
    "print(\"\\n\")\n",
    "\n",
    "#Calcular la precisión\n",
    "from sklearn.metrics import precision_score\n",
    "precision1=precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Mucha disponibilidad en el siguiente mes\")\n",
    "precision2=precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Poca disponibilidad en el siguiente mes\")\n",
    "\n",
    "#Calcular la exactitud\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud=accuracy_score(y_test, y_pred)\n",
    "\n",
    "#Calcular la sensibilidad\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad1=recall_score(y_test, y_pred, average=\"binary\", pos_label=\"Mucha disponibilidad en el siguiente mes\")\n",
    "sensibilidad2=recall_score(y_test, y_pred, average=\"binary\", pos_label=\"Poca disponibilidad en el siguiente mes\")\n",
    "\n",
    "print(\"Precision del modelo Mucha disponibilidad en el siguiente mes:\")\n",
    "print(precision1)\n",
    "print(\"Precision del modelo Poca disponibilidad en el siguiente mes:\")\n",
    "print(precision2)\n",
    "print(\"\\n\")\n",
    "print(\"Exactitud del modelo:\")\n",
    "print(exactitud)\n",
    "print(\"\\n\")\n",
    "print(\"Sensibilidad del modelo Mucha disponibilidad en el siguiente mes:\")\n",
    "print(sensibilidad1)\n",
    "print(\"Sensibilidad del modelo Poca disponibilidad en el siguiente mes:\")\n",
    "print(sensibilidad2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51658f48",
   "metadata": {},
   "source": [
    "### review_scores_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5eb0d0c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(4.5), np.float64(5.0)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Crear categorias a partir de clases\n",
    "Max=df[\"review_scores_rating\"].max()\n",
    "Min=df[\"review_scores_rating\"].min()\n",
    "\n",
    "\n",
    "limites=[Min, Max]\n",
    "limites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3834ca72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declarar dos intervalos\n",
    "intervalos=np.linspace(4.49,5.1, 3)\n",
    "intervalos\n",
    "\n",
    "categorias=[\"Rating de calificación medio\", \"Rating de calificación alto\"]\n",
    "\n",
    "df[\"review_scores_rating\"]=pd.cut(x=df[\"review_scores_rating\"], bins=intervalos, labels=categorias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "60633f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión:\n",
      "[[9404  227]\n",
      " [1292  429]]\n",
      "\n",
      "\n",
      "Precision del modelo Rating de calificación alto:\n",
      "0.8792071802543007\n",
      "Precision del modelo Rating de calificación medio:\n",
      "0.6539634146341463\n",
      "\n",
      "\n",
      "Exactitud del modelo:\n",
      "0.8661909795630726\n",
      "\n",
      "\n",
      "Sensibilidad del modelo Rating de calificación alto:\n",
      "0.9764302772297788\n",
      "Sensibilidad del modelo Rating de calificación medio:\n",
      "0.2492736780941313\n"
     ]
    }
   ],
   "source": [
    "Vars_Indep=df[[\"price\", \"beds\", \"review_scores_cleanliness\", \"bathrooms\", \"review_scores_value\", \"review_scores_location\", \"reviews_per_month\"]]\n",
    "Var_dep=df[\"review_scores_rating\"]\n",
    "\n",
    "X=Vars_Indep\n",
    "y=Var_dep\n",
    "\n",
    "#Dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=None)\n",
    "\n",
    "#Escalar los datos\n",
    "escalar= StandardScaler()\n",
    "\n",
    "X_train=escalar.fit_transform(X_train)\n",
    "X_test=escalar.fit_transform(X_test)\n",
    "\n",
    "#Definir el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo=LogisticRegression()\n",
    "\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "y_pred=algoritmo.predict(X_test)\n",
    "\n",
    "#Matriz de confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz=confusion_matrix(y_test, y_pred)\n",
    "print(\"Matriz de confusión:\")\n",
    "print(matriz)\n",
    "print(\"\\n\")\n",
    "\n",
    "#Calcular la precisión\n",
    "from sklearn.metrics import precision_score\n",
    "precision1=precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Rating de calificación alto\")\n",
    "precision2=precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Rating de calificación medio\")\n",
    "\n",
    "#Calcular la exactitud\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud=accuracy_score(y_test, y_pred)\n",
    "\n",
    "#Calcular la sensibilidad\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad1=recall_score(y_test, y_pred, average=\"binary\", pos_label=\"Rating de calificación alto\")\n",
    "sensibilidad2=recall_score(y_test, y_pred, average=\"binary\", pos_label=\"Rating de calificación medio\")\n",
    "\n",
    "print(\"Precision del modelo Rating de calificación alto:\")\n",
    "print(precision1)\n",
    "print(\"Precision del modelo Rating de calificación medio:\")\n",
    "print(precision2)\n",
    "print(\"\\n\")\n",
    "print(\"Exactitud del modelo:\")\n",
    "print(exactitud)\n",
    "print(\"\\n\")\n",
    "print(\"Sensibilidad del modelo Rating de calificación alto:\")\n",
    "print(sensibilidad1)\n",
    "print(\"Sensibilidad del modelo Rating de calificación medio:\")\n",
    "print(sensibilidad2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2223f547",
   "metadata": {},
   "source": [
    "### number_of_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "32dccc3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.0), np.float64(62.0)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Crear categorias a partir de clases\n",
    "Max=df[\"number_of_reviews\"].max()\n",
    "Min=df[\"number_of_reviews\"].min()\n",
    "\n",
    "\n",
    "limites=[Min, Max]\n",
    "limites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3b198159",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declarar dos intervalos\n",
    "intervalos=np.linspace(-0.1,62.1, 3)\n",
    "intervalos\n",
    "\n",
    "categorias=[\"Pocas calificaciones\", \"Muchas calificaciones\"]\n",
    "\n",
    "df[\"number_of_reviews\"]=pd.cut(x=df[\"number_of_reviews\"], bins=intervalos, labels=categorias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b01e1a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión:\n",
      "[[    0  1177]\n",
      " [    0 10175]]\n",
      "\n",
      "\n",
      "Precision del modelo Muchas calificaciones:\n",
      "0.0\n",
      "Precision del modelo Pocas calificaciones:\n",
      "0.8963178294573644\n",
      "\n",
      "\n",
      "Exactitud del modelo:\n",
      "0.8963178294573644\n",
      "\n",
      "\n",
      "Sensibilidad del modelo Muchas calificaciones:\n",
      "0.0\n",
      "Sensibilidad del modelo Pocas calificaciones:\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "Vars_Indep=df[[\"price\", \"beds\", \"review_scores_cleanliness\", \"bathrooms\", \"review_scores_value\", \"review_scores_location\", \"reviews_per_month\"]]\n",
    "Var_dep=df[\"number_of_reviews\"]\n",
    "\n",
    "X=Vars_Indep\n",
    "y=Var_dep\n",
    "\n",
    "#Dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=None)\n",
    "\n",
    "#Escalar los datos\n",
    "escalar= StandardScaler()\n",
    "\n",
    "X_train=escalar.fit_transform(X_train)\n",
    "X_test=escalar.fit_transform(X_test)\n",
    "\n",
    "#Definir el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo=LogisticRegression()\n",
    "\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "y_pred=algoritmo.predict(X_test)\n",
    "\n",
    "#Matriz de confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz=confusion_matrix(y_test, y_pred)\n",
    "print(\"Matriz de confusión:\")\n",
    "print(matriz)\n",
    "print(\"\\n\")\n",
    "\n",
    "#Calcular la precisión\n",
    "from sklearn.metrics import precision_score\n",
    "precision1=precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Muchas calificaciones\")\n",
    "precision2=precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Pocas calificaciones\")\n",
    "\n",
    "#Calcular la exactitud\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud=accuracy_score(y_test, y_pred)\n",
    "\n",
    "#Calcular la sensibilidad\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad1=recall_score(y_test, y_pred, average=\"binary\", pos_label=\"Muchas calificaciones\")\n",
    "sensibilidad2=recall_score(y_test, y_pred, average=\"binary\", pos_label=\"Pocas calificaciones\")\n",
    "\n",
    "print(\"Precision del modelo Muchas calificaciones:\")\n",
    "print(precision1)\n",
    "print(\"Precision del modelo Pocas calificaciones:\")\n",
    "print(precision2)\n",
    "print(\"\\n\")\n",
    "print(\"Exactitud del modelo:\")\n",
    "print(exactitud)\n",
    "print(\"\\n\")\n",
    "print(\"Sensibilidad del modelo Muchas calificaciones:\")\n",
    "print(sensibilidad1)\n",
    "print(\"Sensibilidad del modelo Pocas calificaciones:\")\n",
    "print(sensibilidad2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
